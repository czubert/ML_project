{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.985117</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.985118</td>\n",
       "      <td>0.985117</td>\n",
       "      <td>12.849981</td>\n",
       "      <td>5.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.984172</td>\n",
       "      <td>0.984172</td>\n",
       "      <td>0.984172</td>\n",
       "      <td>0.984172</td>\n",
       "      <td>15.986667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.976765</td>\n",
       "      <td>0.976765</td>\n",
       "      <td>0.976765</td>\n",
       "      <td>0.976765</td>\n",
       "      <td>11.078879</td>\n",
       "      <td>3.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>12.762221</td>\n",
       "      <td>2.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.959211</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.959209</td>\n",
       "      <td>1.698882</td>\n",
       "      <td>2.000000e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Balanced Accuracy   ROC AUC  F1 Score  \\\n",
       "0    ExtraTreesClassifier  0.985117           0.985118  0.985118  0.985117   \n",
       "1  RandomForestClassifier  0.984172           0.984172  0.984172  0.984172   \n",
       "2       BaggingClassifier  0.976765           0.976765  0.976765  0.976765   \n",
       "3           XGBClassifier  0.967213           0.967213  0.967213  0.967213   \n",
       "4  DecisionTreeClassifier  0.959211           0.959213  0.959213  0.959209   \n",
       "\n",
       "   Time Taken           std  \n",
       "0   12.849981  5.000000e-07  \n",
       "1   15.986667  0.000000e+00  \n",
       "2   11.078879  3.000000e-07  \n",
       "3   12.762221  2.000000e-07  \n",
       "4    1.698882  2.000000e-06  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('models.csv')\n",
    "cols = df.columns[:-1]\n",
    "df['std'] = round(df[cols].std(axis=1),7)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "      <th>Monthly_Income</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Lead_Creation_Date</th>\n",
       "      <th>Loan_Amount_Applied</th>\n",
       "      <th>Loan_Tenure_Applied</th>\n",
       "      <th>Existing_EMI</th>\n",
       "      <th>Employer_Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Processing_Fee</th>\n",
       "      <th>EMI_Loan_Submitted</th>\n",
       "      <th>Filled_Form</th>\n",
       "      <th>Device_Type</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Source</th>\n",
       "      <th>Var4</th>\n",
       "      <th>LoggedIn</th>\n",
       "      <th>Disbursed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID000002C20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>20000</td>\n",
       "      <td>23-May-78</td>\n",
       "      <td>15-May-15</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CYBOSOL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>G</td>\n",
       "      <td>S122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID000004E40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>35000</td>\n",
       "      <td>07-Oct-85</td>\n",
       "      <td>04-May-15</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TATA CONSULTANCY SERVICES LTD (TCS)</td>\n",
       "      <td>...</td>\n",
       "      <td>13.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6762.9</td>\n",
       "      <td>N</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>G</td>\n",
       "      <td>S122</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID000007H20</td>\n",
       "      <td>Male</td>\n",
       "      <td>Panchkula</td>\n",
       "      <td>22500</td>\n",
       "      <td>10-Oct-81</td>\n",
       "      <td>19-May-15</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALCHEMIST HOSPITALS LTD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>B</td>\n",
       "      <td>S143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID000008I30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Saharsa</td>\n",
       "      <td>35000</td>\n",
       "      <td>30-Nov-87</td>\n",
       "      <td>09-May-15</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BIHAR GOVERNMENT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>B</td>\n",
       "      <td>S143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID000009J40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>100000</td>\n",
       "      <td>17-Feb-84</td>\n",
       "      <td>20-May-15</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>GLOBAL EDGE SOFTWARE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Web-browser</td>\n",
       "      <td>B</td>\n",
       "      <td>S134</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Gender       City  Monthly_Income        DOB  \\\n",
       "0  ID000002C20  Female      Delhi           20000  23-May-78   \n",
       "1  ID000004E40    Male     Mumbai           35000  07-Oct-85   \n",
       "2  ID000007H20    Male  Panchkula           22500  10-Oct-81   \n",
       "3  ID000008I30    Male    Saharsa           35000  30-Nov-87   \n",
       "4  ID000009J40    Male  Bengaluru          100000  17-Feb-84   \n",
       "\n",
       "  Lead_Creation_Date  Loan_Amount_Applied  Loan_Tenure_Applied  Existing_EMI  \\\n",
       "0          15-May-15             300000.0                  5.0           0.0   \n",
       "1          04-May-15             200000.0                  2.0           0.0   \n",
       "2          19-May-15             600000.0                  4.0           0.0   \n",
       "3          09-May-15            1000000.0                  5.0           0.0   \n",
       "4          20-May-15             500000.0                  2.0       25000.0   \n",
       "\n",
       "                         Employer_Name  ... Interest_Rate Processing_Fee  \\\n",
       "0                              CYBOSOL  ...           NaN            NaN   \n",
       "1  TATA CONSULTANCY SERVICES LTD (TCS)  ...         13.25            NaN   \n",
       "2              ALCHEMIST HOSPITALS LTD  ...           NaN            NaN   \n",
       "3                     BIHAR GOVERNMENT  ...           NaN            NaN   \n",
       "4                 GLOBAL EDGE SOFTWARE  ...           NaN            NaN   \n",
       "\n",
       "   EMI_Loan_Submitted Filled_Form  Device_Type  Var2  Source  Var4  LoggedIn  \\\n",
       "0                 NaN           N  Web-browser     G    S122     1         0   \n",
       "1              6762.9           N  Web-browser     G    S122     3         0   \n",
       "2                 NaN           N  Web-browser     B    S143     1         0   \n",
       "3                 NaN           N  Web-browser     B    S143     3         0   \n",
       "4                 NaN           N  Web-browser     B    S134     3         1   \n",
       "\n",
       "  Disbursed  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/Train_nyOWmfK.csv', encoding=\"latin1\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# A class to select numerical or categorical columns\n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "    \n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)\n",
    "\n",
    "    \n",
    "class LabelEncoder_new(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class BinEncoder():\n",
    "    def fit(self, X, y=None):\n",
    "        tests = {}\n",
    "        for col in X.columns:\n",
    "            tests[col] = X[col][1]\n",
    "        \n",
    "        for k,v in tests.items():\n",
    "            X[k] = (X[k] == v).astype(int)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        return X\n",
    "        \n",
    "class City():\n",
    "    # # City (feature)\n",
    "    # Splitting data into categories\n",
    "    def fit(self, X, y=None):\n",
    "        self.replace_data_ = dict(pd.cut(X.City.value_counts(),\n",
    "                                 right=True,\n",
    "                                 bins=[0, 100, 1000, 5000, 99999],\n",
    "                                 labels=['S', 'M', 'B', 'L']))\n",
    "        \n",
    "        self.most_frequent_ = np.array(X.City[~X.City.isna()].sample(X.City.isna().sum()))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # splits cities into groups depending on the number of citizens \n",
    "        X['City'].replace(self.replace_data_, inplace=True)\n",
    "        # replaces NaN values with random not NaN values in City feature\n",
    "        X[\"City\"][np.array(X.City.isna())] = self.most_frequent_\n",
    "        return X\n",
    "\n",
    "        \n",
    "class Source():\n",
    "    # # Source (feature)\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X[\"Source\"] = X.Source.apply(lambda x: x if x in [\"S122\", \"S133\"] else \"Other\")\n",
    "\n",
    "        return X\n",
    "\n",
    "    \n",
    "class Income():\n",
    "    #\n",
    "    # # Monthly income (feature)\n",
    "    #\n",
    "    # # checking outliers for this feature\n",
    "    # px.line(data.Monthly_Income.quantile(np.arange(0,1,0.01))).show('browser')  # based on plot we take 95 percentile\n",
    "    # # changing outliers to the value of 95th percentile\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.mask_ = X.Monthly_Income > X.Monthly_Income.quantile(0.95)\n",
    "        self.monthly_income_ = X.Monthly_Income.quantile(0.95)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X.Monthly_Income[self.mask_] = self.monthly_income_\n",
    "        return X\n",
    "\n",
    "    \n",
    "class LoanAmount():\n",
    "    #\n",
    "    # # Loan_Amount_Applied\n",
    "    #\n",
    "    # # getting rid of variables (rows) that consists of nan in this feature\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X.dropna(subset=[\"Loan_Amount_Applied\"], inplace=True)\n",
    "        \n",
    "        return X\n",
    "        \n",
    "\n",
    "class Fillna_new():\n",
    "    #\n",
    "    # # Dealing with nan values\n",
    "    #\n",
    "\n",
    "    # TODO is it a right idea to get rid of nan?\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(-1, inplace=True)\n",
    "\n",
    "    \n",
    "class Show_data():\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        print(pd.DataFrame(X))\n",
    "        return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\envs\\DataSci\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Gender         City  Monthly_Income  Loan_Amount_Applied  \\\n",
      "47918  Female    Bengaluru          187000             500000.0   \n",
      "49607    Male    Bengaluru           20000             100000.0   \n",
      "18068  Female         Kota            8000              50000.0   \n",
      "23878    Male  Kailashahar           19000             200000.0   \n",
      "3408     Male      Chennai           20000             300000.0   \n",
      "...       ...          ...             ...                  ...   \n",
      "6265   Female      Chennai           15000             500000.0   \n",
      "54892    Male       Mumbai           60000            1000000.0   \n",
      "76842  Female       Mumbai           16000             300000.0   \n",
      "860    Female     Rudrapur           11129              75000.0   \n",
      "15795    Male       Mumbai           55500                  0.0   \n",
      "\n",
      "       Loan_Tenure_Applied  Existing_EMI Mobile_Verified  Var5  Var1  \\\n",
      "47918                  4.0      138500.0               N     0  HBXX   \n",
      "49607                  1.0           0.0               Y     3  HBXX   \n",
      "18068                  2.0        1500.0               N     0  HBXX   \n",
      "23878                  0.0        2460.0               Y     1  HBXC   \n",
      "3408                   3.0           0.0               Y     3  HBXC   \n",
      "...                    ...           ...             ...   ...   ...   \n",
      "6265                   4.0           0.0               N     0  HBXX   \n",
      "54892                  2.0           0.0               Y    16  HBXX   \n",
      "76842                  4.0       10000.0               N     0  HBXX   \n",
      "860                    2.0           0.0               N     0  HBXX   \n",
      "15795                  0.0           0.0               Y     9  HCXF   \n",
      "\n",
      "       Loan_Amount_Submitted  Loan_Tenure_Submitted  Interest_Rate  \\\n",
      "47918                    NaN                    NaN            NaN   \n",
      "49607               100000.0                    1.0            NaN   \n",
      "18068                    NaN                    NaN            NaN   \n",
      "23878               200000.0                    5.0          20.00   \n",
      "3408                300000.0                    3.0          20.00   \n",
      "...                      ...                    ...            ...   \n",
      "6265                     NaN                    NaN            NaN   \n",
      "54892               850000.0                    2.0            NaN   \n",
      "76842                    NaN                    NaN            NaN   \n",
      "860                      NaN                    NaN            NaN   \n",
      "15795               970000.0                    5.0          12.99   \n",
      "\n",
      "       Processing_Fee  EMI_Loan_Submitted Filled_Form  Device_Type Var2  \\\n",
      "47918             NaN                 NaN           N  Web-browser    B   \n",
      "49607             NaN                 NaN           N  Web-browser    B   \n",
      "18068             NaN                 NaN           N  Web-browser    B   \n",
      "23878          2000.0             5298.78           Y  Web-browser    B   \n",
      "3408           3000.0            11149.08           N  Web-browser    B   \n",
      "...               ...                 ...         ...          ...  ...   \n",
      "6265              NaN                 NaN           N  Web-browser    B   \n",
      "54892             NaN                 NaN           N  Web-browser    G   \n",
      "76842             NaN                 NaN           N  Web-browser    G   \n",
      "860               NaN                 NaN           N  Web-browser    B   \n",
      "15795          1999.0            22065.52           Y       Mobile    C   \n",
      "\n",
      "      Source  Var4  \n",
      "47918   S137     1  \n",
      "49607   S127     3  \n",
      "18068   S133     1  \n",
      "23878   S159     5  \n",
      "3408    S133     4  \n",
      "...      ...   ...  \n",
      "6265    S133     1  \n",
      "54892   S122     2  \n",
      "76842   S122     1  \n",
      "860     S133     1  \n",
      "15795   S151     5  \n",
      "\n",
      "[43474 rows x 19 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czube\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\czube\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "D:\\python\\envs\\DataSci\\lib\\site-packages\\ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\czube\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3a371188d5c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m\"show\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mShow_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     ])\n\u001b[1;32m--> 122\u001b[1;33m \u001b[0mprepre_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;31m# preprocess_pipeline = FeatureUnion(transformer_list=[\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m             \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;31m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "1. categorial\n",
    "    a) nominal\n",
    "    b) ordered\n",
    "2. Numerical\n",
    "'''\n",
    "\n",
    "data = pd.read_csv('data/Train_nyOWmfK.csv', encoding=\"latin1\")\n",
    "# print(data.shape)\n",
    "# print(data.info())\n",
    "\n",
    "#\n",
    "# # Getting rid of irrelevant features\n",
    "#\n",
    "irrelevant_features = [\"DOB\", \"Lead_Creation_Date\", \"ID\", \"Employer_Name\", \"Salary_Account\"]\n",
    "data.drop(irrelevant_features, axis=1, inplace=True)\n",
    "data.dropna(subset=[\"Loan_Amount_Applied\"], inplace=True)\n",
    "\n",
    "#\n",
    "# # getting X and y \n",
    "#\n",
    "X = data.drop([\"LoggedIn\", \"Disbursed\"], axis=1)\n",
    "y = data.Disbursed\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# # Train, Test, Split\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "#\n",
    "# # Dealing with binary features\n",
    "#    \n",
    "# bin_pipeline = Pipeline([\n",
    "#     (\"select_numeric\", DataFrameSelector(['Gender', 'Mobile_Verified', 'Filled_Form', 'Device_Type'])),\n",
    "#     (\"label_encode\", LabelEncoder_new()),\n",
    "# ])\n",
    "# bin_pipeline.fit_transform(X_train)\n",
    "\n",
    "bin_feature = ['Gender', 'Mobile_Verified', 'Filled_Form', 'Device_Type']\n",
    "\n",
    "bin_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(bin_feature)),\n",
    "    (\"bin\", BinEncoder()),\n",
    "])\n",
    "bin_pipeline.fit_transform(X_train)\n",
    "\n",
    "# # Dealing with numerical features, standarization\n",
    "#\n",
    "# WHAT a lot of values to normalize is set to '-1' which gives negative results after normalization\n",
    "features_to_normalize = ['Loan_Amount_Submitted', 'Loan_Tenure_Submitted', 'Loan_Amount_Applied', 'Loan_Tenure_Applied',\n",
    "                'Var5', 'EMI_Loan_Submitted', 'Processing_Fee', 'Interest_Rate', 'Monthly_Income']\n",
    "# #TODO check if standard scaler or normalization is better for the data\n",
    "num_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(features_to_normalize)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "num_pipeline.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# # # Pipeline for categorical data. Replaces NaN with the most frequent value. Then OneHotEncoding is dividing data\n",
    "to_one_hot = ['Var1', 'City', 'Var2', 'Var4', 'Source']\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(to_one_hot)),\n",
    "    (\"impute\", MostFrequentImputer()),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
    "])\n",
    "cat_pipeline.fit_transform(X_train)\n",
    "\n",
    "city_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(['City'])),\n",
    "    (\"city\", City()),\n",
    "])\n",
    "city_pipeline.fit_transform(X_train)\n",
    "\n",
    "source_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(['Source'])),\n",
    "    (\"source\", Source()),\n",
    "])\n",
    "source_pipeline.fit_transform(X_train)\n",
    "\n",
    "income_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(['Monthly_Income'])),\n",
    "    (\"income\", Income()),\n",
    "])\n",
    "income_pipeline.fit_transform(X_train)\n",
    "\n",
    "loan_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(X_train.columns)),\n",
    "    (\"loan_amount\", LoanAmount()),\n",
    "])\n",
    "loan_pipeline.fit_transform(X_train)\n",
    "\n",
    "fillna_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector(X_train.columns)),\n",
    "    (\"fillna_new\", Fillna_new()),\n",
    "])\n",
    "fillna_pipeline.fit_transform(X_train)    \n",
    "    \n",
    "prepre_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"fillna_pipeline\", fillna_pipeline),\n",
    "#     (\"bin_pipeline\", bin_pipeline),\n",
    "#     (\"city_pipeline\", city_pipeline),\n",
    "#     (\"source_pipeline\", source_pipeline),\n",
    "#     (\"income_pipeline\", income_pipeline),\n",
    "    (\"show\", Show_data()),\n",
    "    ])\n",
    "prepre_pipeline.fit_transform(X_train)    \n",
    "\n",
    "# preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "#     (\"prepre\", prepre_pipeline),\n",
    "#     (\"cat_pipeline\", cat_pipeline),\n",
    "#     (\"num_pipeline\", num_pipeline),\n",
    "#     (\"show\", Show_data()),\n",
    "       \n",
    "# ])\n",
    "    \n",
    "\n",
    "# preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "# #     (\"bin_pipeline\", bin_pipeline),\n",
    "#     (\"fillna_pipeline\", fillna_pipeline),\n",
    "# #     (\"loan_pipeline\", loan_pipeline),\n",
    "#     (\"city_pipeline\", city_pipeline),\n",
    "#     (\"source_pipeline\", source_pipeline),\n",
    "#     (\"income_pipeline\", income_pipeline),\n",
    "#     (\"num_pipeline\", num_pipeline),\n",
    "#     (\"cat_pipeline\", cat_pipeline),   \n",
    "#     ])\n",
    "\n",
    "\n",
    "# #\n",
    "# # # Machine Learning Part\n",
    "# #\n",
    "\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# # DecisionTreeClassifier\n",
    "\n",
    "# from imblearn.pipeline import Pipeline\n",
    "# pipe = Pipeline([\n",
    "#     ('preprocessing', preprocess_pipeline),\n",
    "# #     ('imba', ADASYN()),\n",
    "#     ('classifier', DecisionTreeClassifier()),\n",
    "# ])\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#             'classifier__max_features': [1, 5, 10]\n",
    "# }\n",
    "\n",
    "# grid_1 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
    "# grid_1.fit(X_train, y_train)\n",
    "# grid_1.best_params_\n",
    "\n",
    "# #\n",
    "# # # RandomForestClassifier\n",
    "# #\n",
    "# pipe = Pipeline([\n",
    "#     ('preprocessing', preprocess_pipeline),     \n",
    "#     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#             'classifier__max_features': [1, 5, 10]\n",
    "# }\n",
    "\n",
    "# grid_2 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
    "# grid_2.fit(X_train, y_train)\n",
    "# grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ec6931a00d85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Show the classification report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report_imbalanced\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report_imbalanced\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_1' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced( y_test, grid_1.best_estimator_.predict(X_test) ))\n",
    "print(classification_report_imbalanced( y_test, grid_2.best_estimator_.predict(X_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
